import os
import time
import sys
import traceback
from typing import List
import pandas as pd

import yfinance as yf
from influxdb_client import InfluxDBClient, Point, WriteOptions

VERSION = "fetcher-backfill-v4"

# -----------------------
# Env & defaults
# -----------------------

def get_env(name: str, default: str = "") -> str:
    v = os.getenv(name, default)
    return default if v == "" else v

INFLUX_URL = get_env("INFLUX_URL", "http://influxdb:8086")
INFLUX_TOKEN = get_env("INFLUX_TOKEN")
INFLUX_ORG = get_env("INFLUX_ORG", "stocks")
INFLUX_BUCKET = get_env("INFLUX_BUCKET", "lse")

TICKERS = [t.strip() for t in get_env("TICKERS", "VOD.L,HSBA.L,BP.L").split(",") if t.strip()]
FETCH_INTERVAL_SECONDS = int(get_env("FETCH_INTERVAL_SECONDS", "300"))
YF_INTERVAL = get_env("YF_INTERVAL", "1m")    # e.g., 1m, 2m, 5m, 15m, 30m, 60m, 1d
YF_PERIOD = get_env("YF_PERIOD", "1d")        # used for incremental refresh

BACKFILL_ON_START = get_env("BACKFILL_ON_START", "true").lower() in ("1","true","yes","y")
BACKFILL_PERIOD_ENV = get_env("BACKFILL_PERIOD", "").strip()  # optional override

# -----------------------
# Helpers
# -----------------------

def ensure_utc(ts):
    """Return an aware UTC datetime from pandas/str/naive timestamp-like input."""
    # pd.to_datetime(..., utc=True) handles naive or already-aware inputs.
    return pd.to_datetime(ts, utc=True).to_pydatetime()

def normalize_datetime(df: pd.DataFrame) -> pd.DataFrame:
    """Ensure a 'datetime' column exists and is tz-aware UTC."""
    df = df.reset_index()
    if 'Date' in df.columns:
        df = df.rename(columns={'Date': 'datetime'})
    elif 'Datetime' in df.columns:
        df = df.rename(columns={'Datetime': 'datetime'})
    elif 'index' in df.columns:
        df = df.rename(columns={'index': 'datetime'})
    # Force UTC; safe for naive & aware inputs
    df['datetime'] = pd.to_datetime(df['datetime'], utc=True)
    return df

def default_backfill_period(interval: str) -> str:
    """Return a safe max period Yahoo allows for the given interval."""
    i = interval.lower()
    # Conservative mapping based on Yahoo limits
    if i == "1m":
        return "7d"
    if i in ("2m","5m","15m","30m"):
        return "60d"
    if i in ("60m","90m","1h"):
        return "2y"
    # daily or above
    return "max"

# -----------------------
# Fetch
# -----------------------

def fetch(tickers: List[str], period: str, interval: str) -> pd.DataFrame:
    data = yf.download(
        tickers=tickers,
        period=period,
        interval=interval,
        group_by='ticker',
        auto_adjust=False,
        progress=False,
        threads=True,
    )
    frames = []
    for t in tickers:
        if isinstance(data.columns, pd.MultiIndex):
            if t in data.columns.get_level_values(0):
                df_t = data[t].copy()
            else:
                print(f"[fetch] No data for {t}", file=sys.stderr)
                continue
        else:
            df_t = data.copy()

        if df_t is None or df_t.empty:
            print(f"[fetch] Empty df for {t}", file=sys.stderr)
            continue

        df_t = normalize_datetime(df_t).rename(columns={
            'Open': 'open',
            'High': 'high',
            'Low': 'low',
            'Close': 'close',
            'Adj Close': 'adj_close',
            'Volume': 'volume',
        })
        df_t['ticker'] = t

        # Currency (best-effort)
        currency = ''
        try:
            info = yf.Ticker(t).fast_info
            currency = getattr(info, 'currency', None) or (info.get('currency') if isinstance(info, dict) else None) or ''
        except Exception:
            pass
        df_t['currency'] = currency

        df_t = df_t[['ticker','datetime','open','high','low','close','adj_close','volume','currency']]
        frames.append(df_t)

    if not frames:
        return pd.DataFrame(columns=['ticker','datetime','open','high','low','close','adj_close','volume','currency'])
    return pd.concat(frames, ignore_index=True).sort_values(['ticker','datetime'])

# -----------------------
# Write
# -----------------------

def write_to_influx(df: pd.DataFrame, client: InfluxDBClient, bucket: str, org: str):
    if df.empty:
        print("[influx] nothing to write")
        return
    write_api = client.write_api(write_options=WriteOptions(batch_size=500, flush_interval=5_000, jitter_interval=1_000))

    points = []
    for _, row in df.iterrows():
        ts = ensure_utc(row["datetime"])

        # Tag the exchange (simple heuristic)
        ticker = row["ticker"]
        exchange = "LSE" if ticker.endswith(".L") else "US"

        p = Point("lse_prices") \
            .tag("ticker", ticker) \
            .tag("exchange", exchange) \
            .tag("currency", row.get("currency") or "")

        # Only set fields when present (avoid None issues)
        if pd.notna(row["open"]):      p = p.field("open", float(row["open"]))
        if pd.notna(row["high"]):      p = p.field("high", float(row["high"]))
        if pd.notna(row["low"]):       p = p.field("low",  float(row["low"]))
        if pd.notna(row["close"]):     p = p.field("close", float(row["close"]))
        if pd.notna(row["adj_close"]): p = p.field("adj_close", float(row["adj_close"]))
        if pd.notna(row["volume"]):    p = p.field("volume", int(row["volume"]))

        p = p.time(ts)  # guaranteed UTC
        points.append(p)

    try:
        write_api.write(bucket=bucket, org=org, record=points)
        print(f"[influx] wrote {len(points)} points")
    except Exception as e:
        print(f"[influx] write error: {e}", file=sys.stderr)

# -----------------------
# Main loop
# -----------------------

def backfill_once(client: InfluxDBClient):
    try:
        if not BACKFILL_ON_START:
            print("[backfill] disabled")
            return
        period = BACKFILL_PERIOD_ENV or default_backfill_period(YF_INTERVAL)
        print(f"[backfill] start period={period} interval={YF_INTERVAL} tickers={TICKERS}")
        df = fetch(TICKERS, period, YF_INTERVAL)
        if df.empty:
            print("[backfill] nothing fetched")
            return
        write_to_influx(df, client, INFLUX_BUCKET, INFLUX_ORG)
        print("[backfill] done")
    except Exception as e:
        print(f"[backfill] error: {e}", file=sys.stderr)
        traceback.print_exc()

def main_loop():
    print(f"{VERSION} | InfluxDB: {INFLUX_URL}, org={INFLUX_ORG}, bucket={INFLUX_BUCKET}, tickers={TICKERS}")
    with InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG) as client:
        # One-time backfill
        backfill_once(client)

        # Incremental loop
        while True:
            try:
                df = fetch(TICKERS, YF_PERIOD, YF_INTERVAL)
                # keep recent window to reduce duplicates
                if not df.empty:
                    cutoff = pd.Timestamp.now(tz='UTC') - pd.Timedelta(minutes=30)
                    df = df[df["datetime"] >= cutoff]
                write_to_influx(df, client, INFLUX_BUCKET, INFLUX_ORG)
            except Exception as e:
                print(f"[loop] error: {e}", file=sys.stderr)
                traceback.print_exc()
            time.sleep(FETCH_INTERVAL_SECONDS)

if __name__ == "__main__":
    main_loop()
